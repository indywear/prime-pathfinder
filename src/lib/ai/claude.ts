import OpenAI from 'openai'

const openrouter = new OpenAI({
    baseURL: 'https://openrouter.ai/api/v1',
    apiKey: process.env.OPENROUTER_API_KEY,
})

// AI Models
const MODELS = {
    CLAUDE_OPUS: 'anthropic/claude-3-opus',
    CLAUDE_HAIKU: 'anthropic/claude-3-haiku',
}

// ==================== FEEDBACK GENERATION ====================

interface FeedbackRequest {
    content: string
    taskTitle?: string
    rubrics?: { name: string; description: string; maxScore: number }[]
    nationality: string
    thaiLevel: string
    userName?: string
}

interface FeedbackResponse {
    overallScore: number
    scores: { name: string; score: number; maxScore: number; feedback: string }[]
    generalFeedback: string
    encouragement: string
    improvements: string[]
}

export async function generateFeedback(request: FeedbackRequest): Promise<FeedbackResponse> {
    const defaultRubrics = [
        { name: 'Grammar', description: '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå', maxScore: 25 },
        { name: 'Vocabulary', description: '‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢', maxScore: 25 },
        { name: 'Organization', description: '‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î', maxScore: 25 },
        { name: 'Task Fulfillment', description: '‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô', maxScore: 25 },
    ]

    const rubrics = request.rubrics || defaultRubrics

    const prompt = `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏π‡∏™‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏à‡∏î‡∏µ‡πÅ‡∏•‡∏∞‡∏™‡∏ô‡∏∏‡∏Å‡∏™‡∏ô‡∏≤‡∏ô ‡∏ä‡∏∑‡πà‡∏≠ "‡∏ô‡πâ‡∏≠‡∏á‡πÑ‡∏ó‡∏¢"
‡∏Ñ‡∏∏‡∏ì‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏´‡πâ feedback ‡∏á‡∏≤‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡∏≠‡∏á‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô:
- ‡∏™‡∏±‡∏ç‡∏ä‡∏≤‡∏ï‡∏¥: ${request.nationality}
- ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢: ${request.thaiLevel}
${request.userName ? `- ‡∏ä‡∏∑‡πà‡∏≠: ${request.userName}` : ''}
${request.taskTitle ? `- ‡∏†‡∏≤‡∏£‡∏∞‡∏á‡∏≤‡∏ô: ${request.taskTitle}` : ''}

‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô:
${rubrics.map((r) => `- ${r.name} (${r.maxScore} ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô): ${r.description}`).join('\n')}

‡∏á‡∏≤‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô:
"""
${request.content}
"""

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏´‡πâ feedback ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
{
  "overallScore": <‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°>,
  "scores": [
    {"name": "<‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏ì‡∏ë‡πå>", "score": <‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô>, "maxScore": <‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏ï‡πá‡∏°>, "feedback": "<feedback ‡∏™‡∏±‡πâ‡∏ô‡πÜ>"}
  ],
  "generalFeedback": "<feedback ‡∏£‡∏ß‡∏°‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÉ‡∏™‡πà‡∏≠‡∏µ‡πÇ‡∏°‡∏à‡∏¥>",
  "encouragement": "<‡∏Ñ‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à ‡∏≠‡∏≤‡∏à‡πÉ‡∏™‡πà‡∏°‡∏∏‡∏Å‡∏ï‡∏•‡∏Å‡∏´‡∏£‡∏∑‡∏≠ meme ‡∏†‡∏≤‡∏©‡∏≤${request.nationality}‡πÑ‡∏î‡πâ>",
  "improvements": ["<‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á 1>", "<‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á 2>"]
}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô`

    try {
        const response = await openrouter.chat.completions.create({
            model: MODELS.CLAUDE_OPUS,
            messages: [{ role: 'user', content: prompt }],
            temperature: 0.7,
            max_tokens: 1500,
        })

        const content = response.choices[0]?.message?.content || '{}'
        // Extract JSON from response
        const jsonMatch = content.match(/\{[\s\S]*\}/)
        if (jsonMatch) {
            return JSON.parse(jsonMatch[0]) as FeedbackResponse
        }
        throw new Error('Invalid JSON response')
    } catch (error) {
        console.error('AI Feedback error:', error)
        // Return default response on error
        return {
            overallScore: 0,
            scores: rubrics.map((r) => ({ name: r.name, score: 0, maxScore: r.maxScore, feedback: '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ' })),
            generalFeedback: '‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á',
            encouragement: '‡∏™‡∏π‡πâ‡πÜ ‡∏ô‡∏∞! üí™',
            improvements: [],
        }
    }
}

// ==================== QUESTION GENERATION ====================

interface QuestionRequest {
    gameType: 'vocab' | 'fillblank' | 'arrange' | 'compose' | 'reading'
    difficulty: 1 | 2 | 3
    thaiLevel: string
    count?: number
}

interface Question {
    question: string
    options?: string[]
    correctAnswer: string | number
    explanation?: string
    points: number
}

export async function generateQuestions(request: QuestionRequest): Promise<Question[]> {
    const count = request.count || 5
    const difficultyDesc = request.difficulty === 1 ? '‡∏á‡πà‡∏≤‡∏¢' : request.difficulty === 2 ? '‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á' : '‡∏¢‡∏≤‡∏Å'

    const gamePrompts: Record<string, string> = {
        vocab: `‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ${count} ‡∏Ç‡πâ‡∏≠ ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏µ 4 ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å`,
        fillblank: `‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≥ ${count} ‡∏Ç‡πâ‡∏≠ ‡∏°‡∏µ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á ___ ‡πÅ‡∏•‡∏∞ 4 ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å`,
        arrange: `‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ${count} ‡∏Ç‡πâ‡∏≠ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏¢‡∏Å‡∏°‡∏≤ ‡∏ú‡∏π‡πâ‡πÄ‡∏•‡πà‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å`,
        compose: `‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏à‡∏ó‡∏¢‡πå‡πÅ‡∏ï‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ${count} ‡∏Ç‡πâ‡∏≠ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ`,
        reading: `‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó‡∏≠‡πà‡∏≤‡∏ô‡∏™‡∏±‡πâ‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ${count} ‡∏Ç‡πâ‡∏≠`,
    }

    const prompt = `‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡πà‡∏≤‡∏á‡∏ä‡∏≤‡∏ï‡∏¥
‡∏£‡∏∞‡∏î‡∏±‡∏ö: ${request.thaiLevel}
‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å: ${difficultyDesc}

${gamePrompts[request.gameType]}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON array:
[
  {
    "question": "<‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°>",
    "options": ["<‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 1>", "<‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 2>", ...] (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ),
    "correctAnswer": <index ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ñ‡∏π‡∏Å ‡∏´‡∏£‡∏∑‡∏≠ string ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å>,
    "explanation": "<‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢>",
    "points": <‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 5-15>
  }
]

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô`

    try {
        const response = await openrouter.chat.completions.create({
            model: MODELS.CLAUDE_HAIKU, // Use faster model for questions
            messages: [{ role: 'user', content: prompt }],
            temperature: 0.8,
            max_tokens: 2000,
        })

        const content = response.choices[0]?.message?.content || '[]'
        const jsonMatch = content.match(/\[[\s\S]*\]/)
        if (jsonMatch) {
            return JSON.parse(jsonMatch[0]) as Question[]
        }
        throw new Error('Invalid JSON response')
    } catch (error) {
        console.error('AI Question generation error:', error)
        return []
    }
}

// ==================== HUMOR & ENCOURAGEMENT ====================

interface HumorRequest {
    context: 'correct' | 'incorrect' | 'streak' | 'levelup' | 'nudge' | 'welcome'
    nationality: string
    userName?: string
    additionalContext?: string
}

export async function generateHumor(request: HumorRequest): Promise<string> {
    const contextPrompts: Record<string, string> = {
        correct: '‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡∏≠‡∏ö‡∏ñ‡∏π‡∏Å ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ä‡∏°',
        incorrect: '‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡∏≠‡∏ö‡∏ú‡∏¥‡∏î ‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à',
        streak: '‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ó‡∏≥ streak ‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á ‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à',
        levelup: '‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô level ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏¢‡∏¥‡∏ô‡∏î‡∏µ',
        nudge: '‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡πÅ‡∏ö‡∏ö‡∏Å‡∏ß‡∏ô‡πÜ',
        welcome: '‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÉ‡∏´‡∏°‡πà',
    }

    const prompt = `‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÜ (1-2 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: ${contextPrompts[request.context]}
${request.userName ? `‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô: ${request.userName}` : ''}
‡∏™‡∏±‡∏ç‡∏ä‡∏≤‡∏ï‡∏¥: ${request.nationality}
${request.additionalContext || ''}

‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á:
- ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡∏™‡∏ô‡∏∏‡∏Å‡∏™‡∏ô‡∏≤‡∏ô
- ‡πÉ‡∏™‡πà‡∏≠‡∏µ‡πÇ‡∏°‡∏à‡∏¥
- ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡πÉ‡∏™‡πà‡∏°‡∏∏‡∏Å‡∏ï‡∏•‡∏Å‡∏´‡∏£‡∏∑‡∏≠ meme ‡∏†‡∏≤‡∏©‡∏≤${request.nationality}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏•‡∏¢ (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á JSON)`

    try {
        const response = await openrouter.chat.completions.create({
            model: MODELS.CLAUDE_HAIKU,
            messages: [{ role: 'user', content: prompt }],
            temperature: 0.9,
            max_tokens: 200,
        })

        return response.choices[0]?.message?.content || '‡∏™‡∏π‡πâ‡πÜ ‡∏ô‡∏∞! üí™'
    } catch (error) {
        console.error('AI Humor generation error:', error)
        return '‡∏™‡∏π‡πâ‡πÜ ‡∏ô‡∏∞! üí™'
    }
}

// ==================== AI DETECTION (PLAYFUL) ====================

interface AIDetectionRequest {
    content: string
    timeSpentSeconds: number
    expectedTimeSeconds: number
}

interface AIDetectionResponse {
    suspicious: boolean
    confidence: number
    playfulMessage?: string
}

export async function detectAIUsage(request: AIDetectionRequest): Promise<AIDetectionResponse> {
    // Quick heuristic check first
    const tooFast = request.timeSpentSeconds < request.expectedTimeSeconds * 0.3

    if (!tooFast && request.content.length < 500) {
        return { suspicious: false, confidence: 0 }
    }

    const prompt = `‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ß‡πà‡∏≤‡∏á‡∏≤‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ô‡∏µ‡πâ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢:
- ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ: ${request.timeSpentSeconds} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á: ${request.expectedTimeSeconds} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: ${request.content.length} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£

‡∏á‡∏≤‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô:
"""
${request.content.substring(0, 500)}
"""

‡∏ñ‡πâ‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ AI ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏¢‡∏≠‡∏Å‡∏•‡πâ‡∏≠‡πÅ‡∏ö‡∏ö‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å (‡πÑ‡∏°‡πà‡∏ï‡∏≥‡∏´‡∏ô‡∏¥)

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON:
{
  "suspicious": <true/false>,
  "confidence": <0-100>,
  "playfulMessage": "<‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏¢‡∏≠‡∏Å‡∏•‡πâ‡∏≠‡∏ñ‡πâ‡∏≤ suspicious>"
}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô`

    try {
        const response = await openrouter.chat.completions.create({
            model: MODELS.CLAUDE_HAIKU,
            messages: [{ role: 'user', content: prompt }],
            temperature: 0.5,
            max_tokens: 300,
        })

        const content = response.choices[0]?.message?.content || '{}'
        const jsonMatch = content.match(/\{[\s\S]*\}/)
        if (jsonMatch) {
            return JSON.parse(jsonMatch[0]) as AIDetectionResponse
        }
        return { suspicious: false, confidence: 0 }
    } catch (error) {
        console.error('AI Detection error:', error)
        return { suspicious: false, confidence: 0 }
    }
}

// ==================== GENERAL CHITCHAT (PLAYFUL) ====================

interface ChitchatRequest {
    userId: string
    message: string
    userContext?: {
        name: string
        level: string
        streak: number
        preferredLanguage: string
    }
}

export async function generateChitchat(request: ChitchatRequest): Promise<string> {
    const prompt = `‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ "‡∏ô‡πâ‡∏≠‡∏á‡πÑ‡∏ó‡∏¢" (Nong Thai) AI Companion ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ã‡∏µ‡πâ‡∏ù‡∏∂‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å: ‡∏£‡πà‡∏≤‡πÄ‡∏£‡∏¥‡∏á ‡∏Å‡∏ß‡∏ô‡∏ô‡∏¥‡∏î‡πÜ ‡∏Ç‡∏µ‡πâ‡πÄ‡∏•‡πà‡∏ô ‡∏ä‡∏≠‡∏ö‡∏´‡∏¢‡∏≠‡∏Å‡∏•‡πâ‡∏≠ (Teasing/Playful) ‡πÅ‡∏ï‡πà‡∏Å‡πá‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à
‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡∏≤‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏™‡∏ô‡∏∏‡∏Å ‡∏ú‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏≤‡∏¢ ‡πÅ‡∏ï‡πà‡∏Å‡πá‡πÅ‡∏≠‡∏ö‡πÅ‡∏ó‡∏£‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ö‡πâ‡∏≤‡∏á

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô:
- ‡∏ä‡∏∑‡πà‡∏≠: ${request.userContext?.name || '‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏ä‡∏∑‡πà‡∏≠'}
- ‡∏£‡∏∞‡∏î‡∏±‡∏ö: ${request.userContext?.level || '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'}
- Streak: ${request.userContext?.streak || 0} ‡∏ß‡∏±‡∏ô
- ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏±‡∏î: ${request.userContext?.preferredLanguage || 'TH'}

‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô: "${request.message}"

‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
- ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏ô‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ñ‡πâ‡∏≤‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ñ‡∏ô‡∏±‡∏î‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©)
- ‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ)
- ***‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡∏ô ‡∏Ç‡∏µ‡πâ‡πÄ‡∏•‡πà‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏¢‡∏≠‡∏Å‡∏•‡πâ‡∏≠*** (‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏ã‡∏ß‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Streak, ‡πÅ‡∏ã‡∏ß‡∏ß‡πà‡∏≤‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏ô‡∏≤‡∏ô, ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡πà‡∏ô‡∏°‡∏∏‡∏Å)
- ‡πÉ‡∏™‡πà‡∏≠‡∏µ‡πÇ‡∏°‡∏à‡∏¥‡πÄ‡∏¢‡∏≠‡∏∞‡πÜ

‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:`

    try {
        const response = await openrouter.chat.completions.create({
            model: MODELS.CLAUDE_HAIKU,
            messages: [{ role: 'user', content: prompt }],
            temperature: 0.9, // High creativity
            max_tokens: 300,
        })

        return response.choices[0]?.message?.content || '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ô‡πâ‡∏≠‡∏á‡πÑ‡∏ó‡∏¢‡∏™‡∏°‡∏≠‡∏á‡πÅ‡∏•‡πà‡∏ô‡∏ä‡πâ‡∏≤‡∏à‡∏±‡∏á... ‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö? üòÖ'
    } catch (error) {
        console.error('AI Chitchat error:', error)
        return '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ô‡πâ‡∏≠‡∏á‡πÑ‡∏ó‡∏¢‡∏°‡∏∂‡∏ô‡πÜ ‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢... ‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏≠‡∏∑‡πà‡∏ô‡∏Å‡∏±‡∏ô‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö üòµ‚Äçüí´'
    }
}
